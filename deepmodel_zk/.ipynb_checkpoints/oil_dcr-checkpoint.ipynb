{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepctr_torch.models import DeepFM\n",
    "from deepctr_torch.inputs import  SparseFeat, DenseFeat,get_feature_names\n",
    "import torch\n",
    "data = pd.read_csv('./criteo_sample.txt')\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I'+str(i) for i in range(1, 14)]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0,)\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = MinMaxScaler(feature_range=(0,1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
    "                        for feat in sparse_features]\n",
    "dense_feature_columns = [DenseFeat(feat, 1)\n",
    "                      for feat in dense_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_feature_columns = [SparseFeat(feat, dimension=1e6,use_hash=True) for feat in sparse_features]#The dimension can be set according to data\n",
    "dense_feature_columns = [DenseFeat(feat, 1)\n",
    "                      for feat in dense_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "linear_feature_columns = sparse_feature_columns + dense_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = {name:train[name] for name in feature_names}\n",
    "\n",
    "test_model_input = {name:test[name] for name in feature_names}\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "use_cuda = True\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "\n",
    "model = DeepFM(linear_feature_columns,dnn_feature_columns,task='binary',device=device)\n",
    "model.compile(\"adam\", \"binary_crossentropy\",\n",
    "              metrics=['binary_crossentropy'], )\n",
    "\n",
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 128 samples, validate on 32 samples, 1 steps per epoch\n",
      "Epoch 1/10\n",
      "1s - loss:  0.6975 - binary_crossentropy:  0.6975 - auc:  0.4355 - val_binary_crossentropy:  0.6656 - val_auc:  0.4286\n",
      "Epoch 2/10\n",
      "0s - loss:  0.6088 - binary_crossentropy:  0.6088 - auc:  0.9538 - val_binary_crossentropy:  0.6477 - val_auc:  0.5801\n",
      "Epoch 3/10\n",
      "0s - loss:  0.4963 - binary_crossentropy:  0.4963 - auc:  0.9993 - val_binary_crossentropy:  0.6503 - val_auc:  0.5498\n",
      "Epoch 4/10\n",
      "0s - loss:  0.4042 - binary_crossentropy:  0.4042 - auc:  0.9993 - val_binary_crossentropy:  0.6705 - val_auc:  0.5238\n",
      "Epoch 5/10\n",
      "0s - loss:  0.3120 - binary_crossentropy:  0.3120 - auc:  0.9997 - val_binary_crossentropy:  0.7140 - val_auc:  0.5195\n",
      "Epoch 6/10\n",
      "0s - loss:  0.2245 - binary_crossentropy:  0.2245 - auc:  1.0000 - val_binary_crossentropy:  0.7790 - val_auc:  0.5411\n",
      "Epoch 7/10\n",
      "0s - loss:  0.1524 - binary_crossentropy:  0.1524 - auc:  1.0000 - val_binary_crossentropy:  0.8525 - val_auc:  0.5455\n",
      "Epoch 8/10\n",
      "0s - loss:  0.1017 - binary_crossentropy:  0.1017 - auc:  1.0000 - val_binary_crossentropy:  0.9324 - val_auc:  0.5325\n",
      "Epoch 9/10\n",
      "0s - loss:  0.0692 - binary_crossentropy:  0.0692 - auc:  1.0000 - val_binary_crossentropy:  0.9876 - val_auc:  0.5325\n",
      "Epoch 10/10\n",
      "0s - loss:  0.0489 - binary_crossentropy:  0.0489 - auc:  1.0000 - val_binary_crossentropy:  1.0752 - val_auc:  0.5368\n",
      "\n",
      "test LogLoss 0.4879\n",
      "test AUC 0.6667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from deepctr_torch.models import *\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "import torch\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv('./criteo_sample.txt')\n",
    "\n",
    "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "\n",
    "    data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "    data[dense_features] = data[dense_features].fillna(0, )\n",
    "    target = ['label']\n",
    "\n",
    "    # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "    for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        data[feat] = lbe.fit_transform(data[feat])\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "\n",
    "    # 2.count #unique features for each sparse field,and record dense feature field name\n",
    "\n",
    "    fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
    "                              for feat in sparse_features] + [DenseFeat(feat, 1,)\n",
    "                                                              for feat in dense_features]\n",
    "\n",
    "    dnn_feature_columns = fixlen_feature_columns\n",
    "    linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "    feature_names = get_feature_names(\n",
    "        linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "    # 3.generate input data for model\n",
    "\n",
    "    train, test = train_test_split(data, test_size=0.2)\n",
    "    train_model_input = {name:train[name] for name in feature_names}\n",
    "    test_model_input = {name:test[name] for name in feature_names}\n",
    "\n",
    "    # 4.Define Model,train,predict and evaluate\n",
    "\n",
    "    device = 'cpu'\n",
    "    use_cuda = False\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        print('cuda ready...')\n",
    "        device = 'cuda:0'\n",
    "\n",
    "    model = DeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns, task='binary',\n",
    "                   l2_reg_embedding=1e-5, device=device)\n",
    "\n",
    "    model.compile(\"adagrad\", \"binary_crossentropy\",\n",
    "                  metrics=[\"binary_crossentropy\", \"auc\"],)\n",
    "    model.fit(train_model_input, train[target].values,\n",
    "              batch_size=256, epochs=10, validation_split=0.2, verbose=2)\n",
    "\n",
    "    pred_ans = model.predict(test_model_input, 256)\n",
    "    print(\"\")\n",
    "    print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "    print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      0,       1,       2,       3,       4,       5,       6,       7,\n",
       "             8,       9,      10,      11,      12,      13,      14,      15,\n",
       "            16,      17,      18,      19,      20,      21,      22,      23,\n",
       "            24,      25,      26,      27,      28,      29,      30,      31,\n",
       "            32,      33,      34,      35,      36,      37,      38,      39,\n",
       "            40,      41,      42,      43,      44,      45,      46,      47,\n",
       "            48,      49,      50,      51,      52,      53,      54,      55,\n",
       "            56,      57,      58,      59,      60,      61,      62,      63,\n",
       "            64,      65,      66,      67,      68,      69,      70,      71,\n",
       "            72,      73,      74,      75, 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(76))\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./df_train_76d_full.pkl')\n",
    "dense_features =[0,       1,       2,       3,       4,       5,       6,       7,\n",
    "             8,       9,      10,      11,      12,      13,      14,      15,\n",
    "            16,      17,      18,      19,      20,      21,      22,      23,\n",
    "            24,      25,      26,      27,      28,      29,      30,      31,\n",
    "            32,      33,      34,      35,      36,      37,      38,      39,\n",
    "            40,      41,      42,      43,      44,      45,      46,      47,\n",
    "            48,      49,      50,      51,      52,      53,      54,      55,\n",
    "            56,      57,      58,      59,      60,      61,      62,      63,\n",
    "            64,      65,      66,      67,      68,      69,      70,      71,\n",
    "            72,      73,      74,      75,]\n",
    "data[dense_features] = data[dense_features].fillna(0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_pickle('./df_train_76d_full.pkl')\n",
    "data_test = pd.read_pickle('./df_test_76d_full.pkl')\n",
    "data_val = pd.read_pickle('./df_val_76d_full.pkl')\n",
    "data=pd.concat([data_train, data_test,data_val], axis=0, ignore_index=True)\n",
    "data.to_pickle(\"./df_76d_full_50942.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 32602 samples, validate on 8151 samples, 128 steps per epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [00:26,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26s - loss:  0.6805 - binary_crossentropy:  0.6805 - auc:  0.5365 - val_binary_crossentropy:  0.6791 - val_auc:  0.5506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:06,  4.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b30698cf6d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m                   metrics=[\"binary_crossentropy\", \"auc\"],)\n\u001b[1;32m     64\u001b[0m     model.fit(train_model_input, train[target].values,\n\u001b[0;32m---> 65\u001b[0;31m               batch_size=256, epochs=10, validation_split=0.2, verbose=1)\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mpred_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/Anaconda2/envs/aliatte/lib/python3.6/site-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, initial_epoch, validation_split, validation_data, shuffle)\u001b[0m\n\u001b[1;32m    215\u001b[0m                         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/Anaconda2/envs/aliatte/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/Anaconda2/envs/aliatte/lib/python3.6/site-packages/deepctr_torch/models/deepfm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     82\u001b[0m             dnn_input = combined_dnn_input(\n\u001b[1;32m     83\u001b[0m                 sparse_embedding_list, dense_value_list)\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mdnn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mdnn_logit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mlogit\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdnn_logit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/Anaconda2/envs/aliatte/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/Anaconda2/envs/aliatte/lib/python3.6/site-packages/deepctr_torch/layers/core.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/Anaconda2/envs/aliatte/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/Anaconda2/envs/aliatte/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sw/Anaconda2/envs/aliatte/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from deepctr_torch.models import *\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "import torch\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_pickle('./df_76d_full_50942.pkl')\n",
    "    sparse_features = []\n",
    "    dense_features =[0,       1,       2,       3,       4,       5,       6,       7,\n",
    "             8,       9,      10,      11,      12,      13,      14,      15,\n",
    "            16,      17,      18,      19,      20,      21,      22,      23,\n",
    "            24,      25,      26,      27,      28,      29,      30,      31,\n",
    "            32,      33,      34,      35,      36,      37,      38,      39,\n",
    "            40,      41,      42,      43,      44,      45,      46,      47,\n",
    "            48,      49,      50,      51,      52,      53,      54,      55,\n",
    "            56,      57,      58,      59,      60,      61,      62,      63,\n",
    "            64,      65,      66,      67,      68,      69,      70,      71,\n",
    "            72,      73,      74,      75,]\n",
    "    data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "    data[dense_features] = data[dense_features].fillna(0, )\n",
    "    target = ['label']\n",
    "\n",
    "    # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "    for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        data[feat] = lbe.fit_transform(data[feat])\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "\n",
    "    # 2.count #unique features for each sparse field,and record dense feature field name\n",
    "\n",
    "    fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
    "                              for feat in sparse_features] + [DenseFeat(feat, 1,)\n",
    "                                                              for feat in dense_features]\n",
    "\n",
    "    dnn_feature_columns = fixlen_feature_columns\n",
    "    linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "    feature_names = get_feature_names(\n",
    "        linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "    # 3.generate input data for model\n",
    "\n",
    "    train, test = train_test_split(data, test_size=0.2)\n",
    "    train_model_input = {name:train[name] for name in feature_names}\n",
    "    test_model_input = {name:test[name] for name in feature_names}\n",
    "\n",
    "    # 4.Define Model,train,predict and evaluate\n",
    "\n",
    "    device = 'cpu'\n",
    "    use_cuda = False\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        print('cuda ready...')\n",
    "        device = 'cuda:0'\n",
    "\n",
    "    model = DeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns, task='binary',\n",
    "                   l2_reg_embedding=1e-5, device=device)\n",
    "\n",
    "    model.compile(\"adagrad\", \"binary_crossentropy\",\n",
    "                  metrics=[\"binary_crossentropy\", \"auc\"],)\n",
    "    model.fit(train_model_input, train[target].values,\n",
    "              batch_size=256, epochs=100, validation_split=0.2, verbose=1)\n",
    "\n",
    "    pred_ans = model.predict(test_model_input, 256)\n",
    "    print(\"\")\n",
    "    print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "    print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aliatte]",
   "language": "python",
   "name": "conda-env-aliatte-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
